{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Study for the ART Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "from sklearn.externals import joblib\n",
    "# Network import: should be in the path if framework configured correctly\n",
    "import neuralnet as nn\n",
    "import PyNN.NeuralNet as PyNNet\n",
    "import PyNN.TrnInfo as PyTrnInfo\n",
    "import copy\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import itertools\n",
    "import scipy as sc\n",
    "\n",
    "# Standard styles for each class\n",
    "dashes = [[],[10,10],[10,4,2,4],[10,5,100,5]] \n",
    "colors = ['b','r','g','y']\n",
    "markers= ['o','x','^','d']\n",
    "\n",
    "import matplotlib as mpl\n",
    "#mpl.style.use('bmh')\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['legend.handlelength'] = 3\n",
    "mpl.rcParams['legend.borderpad'] = 0.3\n",
    "mpl.rcParams['legend.numpoints'] = 1\n",
    "\n",
    "\n",
    "\n",
    "classes = np.array(['ClasseA','ClasseB','ClasseC','ClasseD'])\n",
    "noveltyclasses = np.array(['ClasseA','ClasseB','ClasseC','ClasseD'])\n",
    "sonarhome = os.getenv('SONARHOME')\n",
    "sonarnov = os.getenv('SONARNOVELTY')\n",
    "nfft = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "target = {}\n",
    "data_nov = {}\n",
    "cvPar = {}\n",
    "nov_det_classes = {}\n",
    "for nov in noveltyclasses:\n",
    "    fdata = sonarhome + '/data/novelty_' + nov + '_' + str(nfft) + 'nfft.jbl'\n",
    "    obj = joblib.load(fdata)\n",
    "    data[nov] = obj['data']\n",
    "    data_nov[nov] = obj['data_nov']\n",
    "    target[nov] = obj['target']\n",
    "    cvPar[nov] = obj['cvPar']\n",
    "    nov_det_classes[nov] = obj['classes']\n",
    "nPts = data[nov].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PCD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcdnet = {}\n",
    "for nov in noveltyclasses:\n",
    "    pcdnet[nov] = {}\n",
    "    # Deflation (or independent)\n",
    "    filepcd = sonarnov + '/PCD/Deflation/pcddef_' + nov + '_' + str(nfft) + 'nfft.jbl'\n",
    "    pcdnet[nov]['def'] = joblib.load(filepcd)\n",
    "    # Cooperative (or constructive)\n",
    "    filepcd = sonarnov + '/PCD/Constructive/pcdcons_' + nov + '_' + str(nfft) + 'nfft.jbl'\n",
    "    pcdnet[nov]['coo'] = joblib.load(filepcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artnet_coo = {}\n",
    "artnet_def = {}\n",
    "for nov in noveltyclasses:\n",
    "    # Constructive\n",
    "    fileart = sonarnov + 'ART/Constructive/art_pcdcons_' + nov + '_' + str(nfft) + 'nfft.jbl'\n",
    "    obj = joblib.load(fileart)\n",
    "    artnet_coo[nov] = obj['ARTModel'].results\n",
    "    # Deflation\n",
    "    fileart = sonarnov + 'ART/Deflation/art_pcddef_' + nov + '_' + str(nfft) + 'nfft.jbl'\n",
    "    obj = joblib.load(fileart)\n",
    "    NCV = cvPar[nov]['CVNSel']\n",
    "    artnet_def[nov] = obj['ARTModel'].results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ART Cooperative Training Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ART + PCD Classification Efficiency - Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection indexes (SP and PD) for the overall classifier, considering different number of PCD. These results account for the case when the ART is used for identifying the known-classes. The resuls consider the performance of the classifiers for different Cross Validation (CV) training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5), facecolor='w')\n",
    "\n",
    "# SP Index\n",
    "plt.subplot(1,2,1)\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    clsnum = np.nonzero(classes == novcls)[0]\n",
    "    pcd_values = np.array(artnet_coo[novcls][0].keys())\n",
    "    sps = np.array([[cv[pcd].trn_info['SP'] for pcd in cv] \\\n",
    "                                            for cv in artnet_coo[novcls]]) / 100.0    \n",
    "    plt.errorbar(pcd_values, np.mean(sps, axis=0), np.std(sps, axis=0), marker='o',\n",
    "                 label=novcls, color = colors[clsnum])\n",
    "    plt.ylim((plt.axis()[2], 1))\n",
    "    plt.xlabel('# PCD')\n",
    "    plt.ylabel('SP Index')\n",
    "    plt.title('PCD Considering Each Novelty')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper right',ncol=2).get_frame().set_facecolor('1')\n",
    "\n",
    "\n",
    "# Detection efficieny\n",
    "plt.subplot(1,2,2)\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    clsnum = np.nonzero(classes == novcls)[0]\n",
    "    pcd_values = np.array(artnet_coo[novcls][0].keys())\n",
    "    for icls, cls in enumerate(nov_det_classes[novcls]):\n",
    "        effs = np.array([[np.mean([cv[pcd].trn_info['PD_c%i'%icls] for icls in range(len(nov_det_classes[novcls]))])\\\n",
    "                                                            for pcd in cv] \\\n",
    "                                                            for cv in artnet_coo[novcls]]) / 100.0    \n",
    "    plt.errorbar(pcd_values, np.mean(effs, axis=0), np.std(effs, axis=0),marker=markers[clsnum],\n",
    "                 label=novcls, color = colors[clsnum])\n",
    "    plt.ylim((plt.axis()[2], 1))\n",
    "    plt.xlabel('# PCD')\n",
    "    plt.ylabel('Average Detection Effiency')\n",
    "    plt.title('PCD Considering Each Novelty')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper right',ncol=2).get_frame().set_facecolor('1')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ART + PCD Classification Efficiency - Per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ART Models can be used to identify each known-class. The results consider the CV trainings and the different number of PCD used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10), facecolor='w')\n",
    "\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    plt.subplot(2,2,inov+1)\n",
    "    pcd_values = np.array(artnet_coo[novcls][0].keys())\n",
    "    for icls, cls in enumerate(nov_det_classes[novcls]):\n",
    "        clsnum = np.nonzero(classes == cls)[0]\n",
    "        effs = np.array([[cv[pcd].trn_info['PD_c%i'%icls] for pcd in cv] for cv in artnet_coo[novcls]]) / 100.0\n",
    "        plt.errorbar(pcd_values, np.mean(effs, axis=0), np.std(effs, axis=0),marker=markers[clsnum],\n",
    "                     label=cls, color = colors[clsnum])\n",
    "    plt.ylim((plt.axis()[2], 1))\n",
    "    plt.xlabel('# PCD')\n",
    "    plt.ylabel('Detection Effiency')\n",
    "    plt.title('Novelty: ' + novcls)\n",
    "    plt.grid()    \n",
    "    plt.legend(loc='lower left',ncol=3).get_frame().set_facecolor('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary over #PCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance summary for each Novelty class. It shows the results (validation set), for each CV, considering the trigger (green), or the probability of identifying the data as a known-class; the SP index (blue); and the novelty detection rate (black), or the probability that an unknown-class is not detected as if it was known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10), facecolor='w')\n",
    "\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    plt.subplot(2,2,inov+1)\n",
    "    pcd_values = np.array(artnet_coo[novcls][0].keys())\n",
    "    sps = np.array([[cv[pcd].trn_info['SP'] for pcd in cv] for cv in artnet_coo[novcls]]) / 100.0\n",
    "    unmapped = 1-np.array([[cv[pcd].trn_info['Unmapped'] for pcd in cv] for cv in artnet_coo[novcls]]) / 100.0\n",
    "    noveff = np.array([[cv[pcd].trn_info['Novelty'] for pcd in cv] for cv in artnet_coo[novcls]]) / 100.0\n",
    "    plt.errorbar(pcd_values, np.mean(sps, axis=0), np.std(sps, axis=0), fmt = 'ob-', label=u'SP')\n",
    "    plt.errorbar(pcd_values, np.mean(unmapped, axis=0), np.std(unmapped, axis=0), fmt = '^g-', label = u'Trigger')\n",
    "    plt.errorbar(pcd_values, np.mean(noveff, axis=0), np.std(noveff, axis=0), fmt = 'xk-', label='Novelty')\n",
    "    plt.ylim((0, 1))\n",
    "    plt.xlabel('# PCD')\n",
    "    plt.ylabel('Rate')\n",
    "    plt.grid()\n",
    "    plt.title('ART Performance - ' + novcls)\n",
    "    plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for nov in noveltyclasses:\n",
    "    # Constructive\n",
    "    fileart = sonarnov + 'ART/Constructive/art_pcdcons_' + nov + '_' + str(nfft) + 'nfft.jbl'\n",
    "    obj = joblib.load(fileart)\n",
    "    # CV\n",
    "    for icv in range(len(obj['ARTModel'].results)):\n",
    "        # PCD\n",
    "        for npcd in obj['ARTModel'].results[icv].keys():\n",
    "            itrn = obj['ARTModel'].results[icv][npcd].trn_info.itrn\n",
    "            W = pcdnet[nov]['coo']['PCDModel'].results[icv].PCDNets[npcd-1].W[0]\n",
    "            Y = W.dot(data[nov].transpose()).transpose()\n",
    "            \n",
    "            scaler = StandardScaler().fit(Y[itrn])\n",
    "            \n",
    "            obj['ARTModel'].results[icv][npcd].trn_data_norm = scaler\n",
    "    joblib.dump(obj, fileart, compress=9)\n",
    "            \n",
    "        \n",
    "        \n",
    "    # Deflation\n",
    "    fileart = sonarnov + 'ART/Deflation/art_pcddef_' + nov + '_' + str(nfft) + 'nfft.jbl'\n",
    "    obj = joblib.load(fileart)\n",
    "    # CV\n",
    "    for icv in range(len(obj['ARTModel'].results)):\n",
    "        # PCD\n",
    "        for npcd in obj['ARTModel'].results[icv].keys():\n",
    "            itrn = obj['ARTModel'].results[icv][npcd].trn_info.itrn\n",
    "            W = pcdnet[nov]['def']['PCDModel'].results[icv].PCDNets[npcd-1].W[0]\n",
    "            Y = W.dot(data[nov].transpose()).transpose()\n",
    "            \n",
    "            scaler = StandardScaler().fit(Y[itrn])\n",
    "            \n",
    "            obj['ARTModel'].results[icv][npcd].trn_data_norm = scaler\n",
    "    joblib.dump(obj, fileart, compress=9)        \n",
    "\"\"\"    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novelty:  ClasseA\n",
      "Novelty:  ClasseB\n",
      "Novelty:  ClasseC\n",
      "Novelty:  ClasseD\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "npcd = 40\n",
    "art_thrs = np.arange(0.6,1.1,0.05)\n",
    "art_out = {}\n",
    "art_out_nov = {}\n",
    "NCV = cvPar.values()[0]['CVNSel']\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    print 'Novelty: ', novcls\n",
    "    art_out[novcls] = {}\n",
    "    art_out_nov[novcls] = {}\n",
    "    for typ in ('coo','def'):\n",
    "        art_out[novcls][typ] = np.zeros((NCV, target[novcls].shape[0], target[novcls].shape[1]))\n",
    "        art_out_nov[novcls][typ] = np.zeros((NCV, data_nov[novcls].shape[0], target[novcls].shape[1]))\n",
    "    # Cooperative Loop over CV\n",
    "    for icv in range(NCV):\n",
    "        # Normalize output\n",
    "        W = pcdnet[novcls]['coo']['PCDModel'].results[icv].PCDNets[npcd-1].W[0]\n",
    "        Y = W.dot(data[novcls].transpose()).transpose()\n",
    "        Y = artnet_coo[novcls][icv][npcd].outputs(Y, False)\n",
    "        art_out[novcls]['coo'][icv] = Y \n",
    "        ############################################ NOVELTY NORMALIZED OUTPUT\n",
    "        W = pcdnet[novcls]['coo']['PCDModel'].results[icv].PCDNets[npcd-1].W[0]\n",
    "        Y = W.dot(data_nov[novcls].transpose()).transpose()\n",
    "        Y = artnet_coo[novcls][icv][npcd].outputs(Y, False)\n",
    "        art_out_nov[novcls]['coo'][icv] = Y \n",
    "    # Deflation Loop over CV\n",
    "    for icv in range(NCV):\n",
    "        # Normalize output\n",
    "        W = pcdnet[novcls]['def']['PCDModel'].results[icv].PCDNets[npcd-1].W[0]\n",
    "        Y = W.dot(data[novcls].transpose()).transpose()\n",
    "        Y = artnet_def[novcls][icv][npcd].outputs(Y, False)\n",
    "        art_out[novcls]['def'][icv] = Y \n",
    "        ############################################ NOVELTY NORMALIZED OUTPUT\n",
    "        W = pcdnet[novcls]['def']['PCDModel'].results[icv].PCDNets[npcd-1].W[0]\n",
    "        Y = W.dot(data_nov[novcls].transpose()).transpose()\n",
    "        Y = artnet_def[novcls][icv][npcd].outputs(Y, False)\n",
    "        art_out_nov[novcls]['def'][icv] = Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ART - Performance through Radius Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "C = artnet_coo[novcls][icv][npcd].classify(Y, False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687157894737\n",
      "68.7157894737\n"
     ]
    }
   ],
   "source": [
    "idx = np.intersect1d(itst, np.nonzero(T == 2)[0])\n",
    "print (C[idx] == T[idx]).sum() / float(len(idx))\n",
    "print artnet_coo[novcls][icv][npcd].trn_info['PD_c2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "novcls = 'ClasseA'\n",
    "icv = 0\n",
    "\n",
    "# New similarity for the i-th neuron: Shat_i = Radius_i(Eta - 1) + S_i\n",
    "# Where Eta is the radius control parameter (New Radius = Eta * Radius)\n",
    "itst = artnet_coo[novcls][icv][npcd].trn_info.ival\n",
    "itrn = artnet_coo[novcls][icv][npcd].trn_info.itrn\n",
    "T = np.argmax(target[novcls], axis=1)\n",
    "Ycls = np.argmax(art_out[novcls]['coo'][icv], axis=1)\n",
    "Yhat = art_out[novcls]['coo'][icv][:, Ycls]\n",
    "\n",
    "W = pcdnet[novcls]['coo']['PCDModel'].results[icv].PCDNets[npcd-1].W[0]\n",
    "X = W.dot(data[novcls].transpose()).transpose()\n",
    "C = artnet_coo[novcls][icv][npcd].classify(X, False)[0]\n",
    "\n",
    "idx = np.intersect1d(itst, np.nonzero(T == 0)[0])\n",
    "\n",
    "print ((Ycls[idx] == 0) & (Yhat[idx] >= 0)).sum() / float(idx.shape[0])\n",
    "print (C[idx] == 0).sum() / float(idx.shape[0])\n",
    "\n",
    "print artnet_coo[novcls][icv][npcd].trn_info['PD_c0']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ART Node Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "novcls = 'ClasseA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooperative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hits Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there nodes more important than others, considering that they have more hits than others? How does this evolve considering different number of PCD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "hbins = np.arange(0,500, 20)\n",
    "pcd_values = np.array(artnet_coo[novcls][0].keys())\n",
    "mat = [[np.histogram(np.sum(art.neuron_class_hits, axis=1),hbins)[0].tolist() for art in cv.values()] \\\n",
    "                                                                              for cv in artnet_coo[novcls]]\n",
    "mat = np.log10(mat)\n",
    "mat = np.mean(mat, axis=0)\n",
    "ms = plt.matshow(mat, fignum=0, aspect='auto', cmap='gray_r')\n",
    "plt.xlabel('Hits Per Node')\n",
    "plt.ylabel('# PCD')\n",
    "xstep = len(hbins) / len(plt.gca().get_xticks())\n",
    "plt.xticks(range(mat.shape[1]), hbins[1:])\n",
    "\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes(\"right\", \"3%\", pad=\"2%\")\n",
    "\n",
    "plt.colorbar(ms, cax=cax, label='Count of Nodes (log10)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation of Radius and Classes Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the radius impact on the importance of the nodes? The plot shows the max. Class rate (the rate of the class in each node - number of hits for class C / total number of events of class C) and the max. Node freq. (the class that is better represented by this node - number of hits for class C / total number of hits).\n",
    "\n",
    "- Must be for one specific CV because the number of nodes is not constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "icv = 4\n",
    "plt.figure(figsize=(12,12))\n",
    "pcd_values = [4, 10, 20, 40]\n",
    "for ipcd, npcd in enumerate(pcd_values):\n",
    "    plt.subplot(2,2,ipcd+1)\n",
    "    plt.scatter(artnet_coo[novcls][icv][npcd].radius, np.max(artnet_coo[novcls][icv][npcd].neuron_class_rate, axis=1),\n",
    "                color='b', label='Class rate');\n",
    "    plt.scatter(artnet_coo[novcls][icv][npcd].radius, np.max(artnet_coo[novcls][icv][npcd].neuron_class_freq, axis=1),\n",
    "                color='r', label='Node rate');\n",
    "    plt.ylim((0,1))\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Node Radius')\n",
    "    plt.ylabel('Rate')\n",
    "    plt.title('#PCD: %i (CV: %i)'%(npcd, icv))\n",
    "    plt.legend(loc='center left', numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the node radius evolve considering different number of PCD? Isolated events would be mapped with few nodes, with possibly small radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "hbins = np.linspace(0,10, 51)\n",
    "pcd_values = np.array(artnet_coo[novcls][0].keys())\n",
    "mat = [[np.histogram(art.radius,hbins)[0].tolist() for art in cv.values()] \\\n",
    "                                                   for cv in artnet_coo[novcls]]\n",
    "\n",
    "mat = np.mean(mat, axis=0)\n",
    "ms = plt.matshow(mat, fignum=0, aspect='auto', cmap='gray_r',\n",
    "                 extent=[hbins[0], hbins[-1], pcd_values[-1],pcd_values[0]])\n",
    "plt.xlabel('Node Radius')\n",
    "plt.ylabel('# PCD')\n",
    "plt.grid(True)\n",
    "\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes(\"right\", \"3%\", pad=\"2%\")\n",
    "\n",
    "plt.colorbar(ms, cax=cax, label='Count of Nodes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hits Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "hbins = np.arange(0,500, 20)\n",
    "pcd_values = np.array(artnet_coo[novcls][0].keys())\n",
    "mat = [[np.histogram(np.sum(art.neuron_class_hits, axis=1),hbins)[0].tolist() for art in cv.values()] \\\n",
    "                                                                              for cv in artnet_def[novcls]]\n",
    "mat = np.log10(mat)\n",
    "mat = np.mean(mat, axis=0)\n",
    "ms = plt.matshow(mat, fignum=0, aspect='auto', cmap='gray_r')\n",
    "plt.xlabel('Hits Per Node')\n",
    "plt.ylabel('# PCD')\n",
    "xstep = len(hbins) / len(plt.gca().get_xticks())\n",
    "plt.xticks(range(mat.shape[1]), hbins[1:])\n",
    "\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes(\"right\", \"3%\", pad=\"2%\")\n",
    "\n",
    "plt.colorbar(ms, cax=cax, label='Count of Nodes (log10)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation of Radius and Classes Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "icv = 4\n",
    "plt.figure(figsize=(12,12))\n",
    "pcd_values = [4, 10, 20, 40]\n",
    "for ipcd, npcd in enumerate(pcd_values):\n",
    "    plt.subplot(2,2,ipcd+1)\n",
    "    plt.scatter(artnet_def[novcls][icv][npcd].radius, np.max(artnet_def[novcls][icv][npcd].neuron_class_rate, axis=1),\n",
    "                color='b', label='Class rate');\n",
    "    plt.scatter(artnet_def[novcls][icv][npcd].radius, np.max(artnet_def[novcls][icv][npcd].neuron_class_freq, axis=1),\n",
    "                color='r', label='Node rate');\n",
    "    plt.ylim((0,1))\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Node Radius')\n",
    "    plt.ylabel('Rate')\n",
    "    plt.title('#PCD: %i (CV: %i)'%(npcd, icv))\n",
    "    plt.legend(loc='center left', numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "hbins = np.linspace(0,int(artnet_def[novcls][0].values()[-1].radius.max()), 51)\n",
    "pcd_values = np.array(artnet_def[novcls][0].keys())\n",
    "mat = [[np.histogram(art.radius,hbins)[0].tolist() for art in cv.values()] \\\n",
    "                                                   for cv in artnet_def[novcls]]\n",
    "\n",
    "mat = np.mean(mat, axis=0)\n",
    "ms = plt.matshow(mat, fignum=0, aspect='auto', cmap='gray_r',\n",
    "                 extent=[hbins[0], hbins[-1], pcd_values[-1],pcd_values[0]])\n",
    "plt.xlabel('Node Radius')\n",
    "plt.ylabel('# PCD')\n",
    "plt.grid(True)\n",
    "\n",
    "divider = make_axes_locatable(plt.gca())\n",
    "cax = divider.append_axes(\"right\", \"3%\", pad=\"2%\")\n",
    "\n",
    "plt.colorbar(ms, cax=cax, label='Count of Nodes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "art_thrs = np.arange(0,1.01,0.005)\n",
    "art_winner = {}\n",
    "art_winner_nov = {}\n",
    "art_out = {}\n",
    "art_out_nov = {}\n",
    "art_error = {}\n",
    "art_raw_data = {}\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    print 'Novelty: ', novcls\n",
    "    art_out[novcls] = np.zeros((NCV, target[novcls].shape[0], target[novcls].shape[1]))\n",
    "    art_out_nov[novcls] = np.zeros((NCV, data_nov[novcls].shape[0], target[novcls].shape[1]))\n",
    "    art_winner[novcls] = np.zeros((NCV, target[novcls].shape[0]))\n",
    "    art_winner_nov[novcls] = np.zeros((NCV, data_nov[novcls].shape[0]))    \n",
    "    art_error[novcls] = np.zeros((NCV, art_thrs.shape[0]))\n",
    "    # Loop over CV\n",
    "    for icv in range(NCV):\n",
    "        # Normalize output\n",
    "        Y = pcdnet[novcls][icv].W[0].dot(data[novcls].T).T\n",
    "        Y = artnet[novcls][icv].trn_data_norm.transform(Y) \n",
    "        R = artnet[novcls][icv].trn_initial_radius\n",
    "        Y = artnet[novcls][icv].outputs(Y)\n",
    "        art_out[novcls][icv] = Y \n",
    "        \"\"\"\n",
    "        dmax = 5*R\n",
    "        art_norm[novcls][icv] = np.tanh(Y/dmax)\n",
    "        art_norm[novcls][icv] = 1 - art_norm[novcls][icv] # Invert: close to 1 is good!\n",
    "        # Adjust range\n",
    "        art_norm[novcls][icv][art_norm[novcls][icv] < 0.5] = 0.5\n",
    "        art_norm[novcls][icv][art_norm[novcls][icv] > 0.9] = 0.9\n",
    "        art_norm[novcls][icv] = (art_norm[novcls][icv] - 0.5) / 0.4 \n",
    "        # Estimate Error from test set\n",
    "        itrn = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        Y = art_norm[novcls][icv][itrn]\n",
    "        T = target[novcls][itrn]\n",
    "        Ymax = np.max(Y, axis=1)\n",
    "        Ymax = Ymax[np.argmax(Y, axis=1) != np.argmax(T, axis=1)]\n",
    "        art_error[novcls][icv] = np.array([(Ymax >= th).sum() for th in art_thrs]) / float(len(itrn))\n",
    "        \"\"\"\n",
    "        ############################################ NOVELTY NORMALIZED OUTPUT\n",
    "        Y = pcdnet[novcls][icv].W[0].dot(data_nov[novcls].T).T\n",
    "        Y = artnet[novcls][icv].trn_data_norm.transform(Y)\n",
    "        Y = artnet[novcls][icv].outputs(Y)\n",
    "        art_out_nov[novcls][icv] = Y \n",
    "        \n",
    "        \"\"\"\n",
    "        Y = artnet[novcls][icv].outputs(Y)\n",
    "        art_norm_nov[novcls][icv] = np.tanh(Y/dmax)\n",
    "        art_norm_nov[novcls][icv] = 1 - art_norm_nov[novcls][icv]\n",
    "        # Adjust range\n",
    "        art_norm_nov[novcls][icv][art_norm_nov[novcls][icv] < 0.5] = 0.5\n",
    "        art_norm_nov[novcls][icv][art_norm_nov[novcls][icv] > 0.9] = 0.9\n",
    "        art_norm_nov[novcls][icv] = (art_norm_nov[novcls][icv] - 0.5) / 0.4         \n",
    "        \"\"\"\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(cvPar[novcls]['Indexes'][icv]['ITrn'])\n",
    "print len(artnet[novcls][icv].neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "icv = 0\n",
    "novcls = 'ClasseA'\n",
    "plt.figure(figsize=(12, 16))\n",
    "nclasses = len(pcdlabels[novcls])\n",
    "for icls, cls in enumerate(pcdlabels[novcls]):\n",
    "    radius = artnet[novcls][icv].trn_initial_radius\n",
    "    ##### Known classes\n",
    "    itgt = target[novcls][:,icls] == 1\n",
    "    for iout in range(art_out[novcls][icv].shape[1]):\n",
    "        plt.subplot((nclasses + 1),(nclasses),(icls * nclasses) + iout + 1)\n",
    "        plt.hist(art_out[novcls][icv][itgt, iout], 100, color='k')\n",
    "        plt.yscale('log')\n",
    "        plt.xlim([-1, np.max(art_out[novcls][icv][itgt,:])])\n",
    "        plt.plot([radius, radius], plt.axis()[2:],'--r',lw=3)\n",
    "        if icls == 0:\n",
    "            plt.title(pcdlabels[novcls][iout])\n",
    "    # Truth label\n",
    "    plt.subplot((nclasses + 1),(nclasses),(icls * nclasses) + 1)\n",
    "    plt.ylabel('Truth: ' + cls)\n",
    "##### Novelty\n",
    "for iout in range(art_out_nov[novcls][icv].shape[1]):\n",
    "    plt.subplot((nclasses + 1),(nclasses),nclasses*nclasses + iout + 1)\n",
    "    plt.hist(art_out_nov[novcls][icv][:, iout], 100, color='k')\n",
    "    plt.yscale('log')\n",
    "    plt.xlim([-1, np.max(art_out_nov[novcls][icv])])\n",
    "    plt.plot([radius, radius], plt.axis()[2:],'--r',lw=3)    \n",
    "    if iout == 0:\n",
    "        plt.ylabel('Truth: Novelty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Contention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "novcls = 'ClasseA'\n",
    "icv = 0\n",
    "npcd = 30\n",
    "\n",
    "itrn = cvPar[novcls]['Indexes'][icv]['ITrn']\n",
    "ival = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "\n",
    "Xart = pcdnet[novcls][icv].W[0].dot(data[novcls].T).T\n",
    "Xart = artnet[novcls][icv].trn_data_norm.transform(Xart) \n",
    "R = artnet[novcls][icv].trn_initial_radius\n",
    "Yart = artnet[novcls][icv].classify(Xart)[1]\n",
    "art_target = np.argmax(target[novcls], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "dim1 = 7\n",
    "dim2 = 23\n",
    "\n",
    "# Truth\n",
    "plt.subplot(1,2,1)\n",
    "for clsnum, cls in enumerate(pcdlabels[novcls]):\n",
    "    icls = np.nonzero(classes == cls)[0][0] \n",
    "    idx = np.intersect1d(itrn, np.nonzero(art_target == clsnum)[0])\n",
    "    plt.plot(Xart[idx, dim1], Xart[idx, dim2], '.', color=colors[icls], alpha=0.1)\n",
    "for ineuron in range(artnet[novcls][icv].neurons.shape[0]):\n",
    "    clsnum = int(artnet[novcls][icv].classes[ineuron])\n",
    "    if clsnum != -1: icls = np.nonzero(classes == pcdlabels[novcls][clsnum])[0][0]\n",
    "    c = colors[icls] if clsnum != -1 else 'k'\n",
    "    plt_neuron = plt.Circle(artnet[novcls][icv].neurons[ineuron,[dim1, dim2]],\n",
    "                            artnet[novcls][icv].radius[ineuron],color=c,fill=False)\n",
    "    plt.gca().add_artist(plt_neuron)\n",
    "plt.axis('equal')\n",
    "plt.title('Truth')\n",
    "plt.xlabel('Dim '+str(dim1))\n",
    "plt.ylabel('Dim '+str(dim2))\n",
    "# Simulation\n",
    "plt.subplot(1,2,2)\n",
    "for cls in np.unique(Yart):\n",
    "    #if cls != -1: continue\n",
    "    idx = np.intersect1d(ival, np.nonzero(Yart == cls)[0])\n",
    "    if cls == -1:\n",
    "        c = 'k'\n",
    "    else:\n",
    "        clsname = pcdlabels[novcls][int(cls)]\n",
    "        c = colors[np.nonzero(classes == clsname)[0][0]]\n",
    "    plt.plot(Xart[idx, dim1], Xart[idx, dim2], '.', color=c, alpha=0.1)\n",
    "for ineuron in range(artnet[novcls][icv].neurons.shape[0]):\n",
    "    clsnum = int(artnet[novcls][icv].classes[ineuron])\n",
    "    if clsnum != -1: icls = np.nonzero(classes == pcdlabels[novcls][clsnum])[0][0]\n",
    "    c = colors[icls] if clsnum != -1 else 'k'\n",
    "    plt_neuron = plt.Circle(artnet[novcls][icv].neurons[ineuron,[dim1, dim2]],\n",
    "                            artnet[novcls][icv].radius[ineuron],color=c,fill=False)\n",
    "    plt.gca().add_artist(plt_neuron)\n",
    "plt.axis('equal')\n",
    "plt.title('Classification')\n",
    "plt.xlabel('Dim '+str(dim1))\n",
    "plt.ylabel('Dim '+str(dim2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ART Normalized Output and Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "art_thrs = np.arange(0,1.01,0.005)\n",
    "art_norm = {}\n",
    "art_norm_nov = {}\n",
    "art_error = {}\n",
    "art_raw_data = {}\n",
    "nsamples = 1000\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    print 'Novelty: ', novcls\n",
    "    art_norm[novcls] = np.zeros((NCV, target[novcls].shape[0], target[novcls].shape[1]))\n",
    "    art_norm_nov[novcls] = np.zeros((NCV, data_nov[novcls].shape[0], target[novcls].shape[1]))\n",
    "    art_error[novcls] = np.zeros((NCV, art_thrs.shape[0]))\n",
    "    # Loop over CV\n",
    "    for icv in range(NCV):\n",
    "        # Normalize output\n",
    "        Y = pcdnet[novcls][icv].W[0].dot(data[novcls].T).T\n",
    "        Y = artnet[novcls][icv].trn_data_norm.transform(Y) \n",
    "        R = artnet[novcls][icv].trn_initial_radius\n",
    "        Y = artnet[novcls][icv].outputs(Y)\n",
    "        dmax = 5*R\n",
    "        art_norm[novcls][icv] = np.tanh(Y/dmax)\n",
    "        art_norm[novcls][icv] = 1 - art_norm[novcls][icv] # Invert: close to 1 is good!\n",
    "        # Adjust range\n",
    "        art_norm[novcls][icv][art_norm[novcls][icv] < 0.5] = 0.5\n",
    "        art_norm[novcls][icv][art_norm[novcls][icv] > 0.9] = 0.9\n",
    "        art_norm[novcls][icv] = (art_norm[novcls][icv] - 0.5) / 0.4 \n",
    "        # Estimate Error from test set\n",
    "        itrn = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        Y = art_norm[novcls][icv][itrn]\n",
    "        T = target[novcls][itrn]\n",
    "        Ymax = np.max(Y, axis=1)\n",
    "        Ymax = Ymax[np.argmax(Y, axis=1) != np.argmax(T, axis=1)]\n",
    "        art_error[novcls][icv] = np.array([(Ymax >= th).sum() for th in art_thrs]) / float(len(itrn))\n",
    "        ############################################ NOVELTY NORMALIZED OUTPUT\n",
    "        Y = pcdnet[novcls][icv].W[0].dot(data_nov[novcls].T).T\n",
    "        Y = artnet[novcls][icv].trn_data_norm.transform(Y)\n",
    "        Y = artnet[novcls][icv].outputs(Y)\n",
    "        art_norm_nov[novcls][icv] = np.tanh(Y/dmax)\n",
    "        art_norm_nov[novcls][icv] = 1 - art_norm_nov[novcls][icv]\n",
    "\n",
    "        # Adjust range\n",
    "        art_norm_nov[novcls][icv][art_norm_nov[novcls][icv] < 0.5] = 0.5\n",
    "        art_norm_nov[novcls][icv][art_norm_nov[novcls][icv] > 0.9] = 0.9\n",
    "        art_norm_nov[novcls][icv] = (art_norm_nov[novcls][icv] - 0.5) / 0.4         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ERROR\n",
    "plt.figure()\n",
    "workclass = 'ClasseA'\n",
    "plt.errorbar(art_thrs, np.mean(art_error[workclass], axis=0), np.std(art_error[workclass], axis=0), errorevery=10)\n",
    "plt.ylabel('Decision error rate (Test set)')\n",
    "plt.xlabel('ART Decision Threshold')\n",
    "plt.xlim([0,1])\n",
    "#plt.ylim([0,1])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "workclass = 'ClasseD'\n",
    "testclass = 'ClasseB'\n",
    "icv = 0\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.suptitle('Novelty: ' + workclass+ '. Distance to ' + testclass + ' nodes')\n",
    "# Non-normalized\n",
    "plt.subplot(3,1,1)\n",
    "Y = pcdnet[workclass][icv].W[0].dot(data[workclass].T).T\n",
    "Y = artnet[workclass][icv].trn_data_norm.transform(Y) \n",
    "R = artnet[workclass][icv].trn_initial_radius\n",
    "Y = artnet[workclass][icv].outputs(Y)\n",
    "dmax = 5*R\n",
    "plt.hist(Y[:,0], 100);\n",
    "ax = plt.axis()\n",
    "plt.plot([dmax, dmax], [ax[2], ax[3]], '--r',lw=3)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Non-normalized ART Distance')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "# Normalized by the tanh and 5*radius\n",
    "plt.subplot(3,1,2)\n",
    "Y = 1 - np.tanh(Y/dmax) \n",
    "plt.hist(Y[:,0], 100);\n",
    "ax = plt.axis()\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Normalized ART Distance by 1 - tanh(Y/(5*Radius))')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "# Afer full normalization\n",
    "plt.subplot(3,1,3)\n",
    "plt.hist(art_norm[workclass][icv][:,0], 100);\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('ART Distance re-normalized to previous [0.5, 0.9]')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Output and Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp_out = {}\n",
    "mlp_out_nov = {}\n",
    "mlp_error = {}\n",
    "mlp_thrs = np.arange(-1,1.01,0.01)\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    print 'Novelty: ', novcls\n",
    "    mlp_out[novcls] = np.zeros((NCV, target[novcls].shape[0], target[novcls].shape[1]))\n",
    "    mlp_out_nov[novcls] = np.zeros((NCV, data_nov[novcls].shape[0], target[novcls].shape[1]))\n",
    "    mlp_error[novcls] = np.zeros((NCV, len(mlp_thrs)))\n",
    "    # Loop over CV\n",
    "    for icv in range(NCV):\n",
    "        # Known-classes\n",
    "        itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        T = target[novcls]\n",
    "        if PCDType == 'pcd_constructive':\n",
    "            Y = pcdnet[novcls][icv].feedforward(data[novcls])\n",
    "        elif PCDType == 'pcd_independent':\n",
    "            Y = pcdclf[novcls][icv].feedforward(pcdnet[novcls][icv].feedforward(data[novcls]))\n",
    "        mlp_out[novcls][icv] = Y\n",
    "        Ytst = Y[itst]\n",
    "        Ttst = T[itst]\n",
    "        Ymax = np.max(Ytst, axis=1)\n",
    "        Ymax = Ymax[np.argmax(Ytst, axis=1) != np.argmax(Ttst, axis=1)]\n",
    "        mlp_error[novcls][icv] = np.array([(Ymax>=th).sum() for th in mlp_thrs]) / float(len(Ytst))\n",
    "        # NOVELTY\n",
    "        if PCDType == 'pcd_constructive':\n",
    "            Y = pcdnet[novcls][icv].feedforward(data_nov[novcls])\n",
    "        elif PCDType == 'pcd_independent':\n",
    "            Y = pcdclf[novcls][icv].feedforward(pcdnet[novcls][icv].feedforward(data_nov[novcls]))\n",
    "        mlp_out_nov[novcls][icv] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ERROR\n",
    "plt.figure()\n",
    "plt.errorbar(mlp_thrs, np.mean(mlp_error[workclass], axis=0), np.std(mlp_error[workclass], axis=0), errorevery=10)\n",
    "plt.ylabel('Decision error rate (Train set)')\n",
    "plt.xlabel('MLP Decision Threshold')\n",
    "plt.xlim([0,1])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ART Single Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10), facecolor='w')\n",
    "det_target = 0.8\n",
    "art_det_thr = {}\n",
    "best_art = {}\n",
    "# Loop over novelties\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    plt.subplot(2,2,inov+1)\n",
    "    NCV = cvPar[novcls]['CVNSel']\n",
    "    # PLot Known classes\n",
    "    effnov = np.zeros((NCV, len(art_thrs)))*np.nan  # novely efficiency\n",
    "    effclass  = np.zeros((target[novcls].shape[1], NCV, len(art_thrs)))\n",
    "    for iout in range(target[novcls].shape[1]):\n",
    "        # Loop over cross-validation\n",
    "        tpr = np.zeros((NCV, len(art_thrs))) * np.nan # true positive rate\n",
    "        for icv in range(NCV):\n",
    "            itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "            Yout = art_norm[novcls][icv][itst]\n",
    "            T = target[novcls][itst]\n",
    "            # Loop over thresholds\n",
    "            for ithr, thr in enumerate(art_thrs):\n",
    "                # True Positive: greater than the threshold and the other neurons.\n",
    "                TP = np.sum((Yout[:, iout]>=thr) & (np.argmax(Yout, axis=1) == iout) & (T[:, iout] == 1))\n",
    "                tpr[icv,ithr] = TP / float(np.sum((T[:, iout] == 1)))                \n",
    "        effclass[iout] = tpr\n",
    "        # Plot\n",
    "        icls = np.nonzero(classes == pcdlabels[novcls][iout])[0][0]\n",
    "        plt.errorbar(art_thrs, np.nanmean(tpr, axis=0), np.nanstd(tpr, axis=0), dashes=dashes[icls],\n",
    "                     color=colors[icls], errorevery=10, label=pcdlabels[novcls][iout])\n",
    "    # Plot SP\n",
    "    effsp = np.sqrt(np.power(np.prod(effclass, axis=0), 1.0/T.shape[1]) * np.mean(effclass, axis=0))\n",
    "    plt.errorbar(art_thrs, np.mean(effsp, axis=0), np.std(effsp, axis=0), fmt='k', dashes=[30, 5, 10, 5],\n",
    "                 errorevery=10, label='SP index')\n",
    "    # Plot total accuracy (efficiency of known-classes)\n",
    "    efftot = np.zeros((NCV, len(art_thrs)))*np.nan  # total efficiency (known-classes)    \n",
    "    for icv in range(NCV):\n",
    "        itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        Yout = art_norm[novcls][icv][itst]\n",
    "        T = target[novcls][itst]\n",
    "        # Loop over thresholds\n",
    "        for ithr, thr in enumerate(art_thrs):\n",
    "            # True Positive: greater than the threshold and correct neuron.\n",
    "            TP = np.sum(((np.max(Yout, axis=1) >= thr) & (np.argmax(Yout, axis=1) == np.argmax(T, axis=1))))\n",
    "            efftot[icv,ithr] = TP / float(Yout.shape[0])\n",
    "    plt.errorbar(art_thrs, np.mean(efftot, axis=0), np.std(efftot, axis=0), fmt='--k',\n",
    "                 errorevery=10, label='Accuracy')\n",
    "    # System trigger (detection rate)\n",
    "    efftrg = np.zeros((NCV, len(art_thrs)))*np.nan  # total efficiency (known-classes)    \n",
    "    for icv in range(NCV):\n",
    "        itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        Yout = art_norm[novcls][icv][itst]\n",
    "        # Loop over thresholds\n",
    "        for ithr, thr in enumerate(art_thrs):\n",
    "            # Just need an output greater than the thrshold\n",
    "            TP = np.sum((np.max(Yout, axis=1)>=thr))\n",
    "            efftrg[icv,ithr] = TP / float(Yout.shape[0])\n",
    "    plt.errorbar(art_thrs, np.mean(efftrg, axis=0), np.std(efftrg, axis=0), fmt='-.k',\n",
    "                 errorevery=10, label='Trigger')\n",
    "    \n",
    "    # Plot Novelty\n",
    "    for icv in range(NCV):\n",
    "        Ynov = art_norm_nov[novcls][icv]\n",
    "        effnov[icv] = np.array([np.sum(np.max(Ynov, axis=1) < thr) for thr in art_thrs], 'f')/Ynov.shape[0]\n",
    "    plt.errorbar(art_thrs, np.nanmean(effnov, axis=0), np.nanstd(effnov, axis=0),\n",
    "                 fmt='k-', errorevery=10, label='Novelty')\n",
    "    # PRINT INFO\n",
    "    idx = np.nonzero(np.mean(efftrg, axis=0) >= det_target)[0][-1]\n",
    "    idx = np.nonzero(np.mean(efftrg, axis=0) >= det_target)[0][-1]\n",
    "    idx = np.nonzero(np.mean(efftot, axis=0) >= det_target)[0][-1]    \n",
    "    print novcls, '  Trig: %5.2f +- %5.2f, Nov: %5.2f +- %5.2f, at thrs: %5.3f'%(np.mean(efftrg, axis=0)[idx]*100,\n",
    "                                                                                 np.std (efftrg, axis=0)[idx]*100,\n",
    "                                                                                 np.mean(effnov, axis=0)[idx]*100,\n",
    "                                                                                 np.std (effnov, axis=0)[idx]*100,\n",
    "                                                                                 art_thrs[idx]),\n",
    "    print ' acc: %5.2f +- %5.2f'%(np.mean(efftot, axis=0)[idx]*100, np.std(efftot, axis=0)[idx]*100),\n",
    "    print ' sp: %5.2f +- %5.2f'%(np.mean(effsp, axis=0)[idx]*100, np.std(effsp, axis=0)[idx]*100)\n",
    "    # Operation parameters\n",
    "    best_art[novcls] = efftrg[:,idx].argmax()\n",
    "    art_det_thr[novcls] = art_thrs[idx]\n",
    "    # Plot aspects\n",
    "    plt.gca().set_yticks(np.linspace(0,1,11))\n",
    "    plt.gca().set_xticks(np.arange(0,1.25,0.25))\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.grid()\n",
    "    plt.title('Novelty: ' + novcls)\n",
    "    plt.xlabel('Decision Threshold')\n",
    "    plt.ylabel('Efficiency/Outlier Rate')\n",
    "    plt.legend(loc='center right').get_frame().set_facecolor('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MLP Single Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10), facecolor='w')\n",
    "det_target = 0.8\n",
    "mlp_det_thr = {}\n",
    "best_mlp = {}\n",
    "# Loop over novelties\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    plt.subplot(2,2,inov+1)\n",
    "    NCV = cvPar[novcls]['CVNSel']\n",
    "    T = target[novcls]\n",
    "    # PLot Known classes\n",
    "    effnov = np.zeros((NCV, len(mlp_thrs)))*np.nan  # novely efficiency\n",
    "    effclass  = np.zeros((T.shape[1], NCV, len(mlp_thrs)))\n",
    "    for iout in range(T.shape[1]):\n",
    "        # Loop over cross-validation\n",
    "        tpr = np.zeros((NCV, len(mlp_thrs))) * np.nan # true positive rate\n",
    "        for icv in range(NCV):\n",
    "            Yout = mlp_out[novcls][icv]\n",
    "            itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "            # Loop over thresholds\n",
    "            for ithr, thr in enumerate(mlp_thrs):\n",
    "                # True Positive: greater than the threshold and the other neurons.\n",
    "                TP = np.sum((Yout[itst, iout]>=thr) & (np.argmax(Yout[itst], axis=1) == iout) & (T[itst, iout] == 1))\n",
    "                tpr[icv,ithr] = TP / float(np.sum((T[itst, iout] == 1)))\n",
    "        effclass[iout] = tpr\n",
    "        # Plot\n",
    "        icls = np.nonzero(classes == pcdlabels[novcls][iout])[0][0]\n",
    "        plt.errorbar(mlp_thrs, np.nanmean(tpr, axis=0), np.nanstd(tpr, axis=0), dashes=dashes[icls],\n",
    "                     color=colors[icls], errorevery=10, label=pcdlabels[novcls][iout])\n",
    "    # Plot SP\n",
    "    effsp = np.sqrt(np.power(np.prod(effclass, axis=0), 1.0/T.shape[1]) * np.mean(effclass, axis=0))\n",
    "    plt.errorbar(mlp_thrs, np.mean(effsp, axis=0), np.std(effsp, axis=0), fmt='k', dashes=[30, 5, 10, 5],\n",
    "                 errorevery=10, label='SP index')\n",
    "    # Plot total accuracy (efficiency of known-classes)\n",
    "    efftot = np.zeros((NCV, len(mlp_thrs)))*np.nan  # total efficiency (known-classes)    \n",
    "    for icv in range(NCV):\n",
    "        Yout = mlp_out[novcls][icv]\n",
    "        itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        # Loop over thresholds\n",
    "        for ithr, thr in enumerate(mlp_thrs):\n",
    "            # True Positive: greater than the threshold and correct neuron.\n",
    "            TP = np.sum(((np.max(Yout, axis=1) >= thr) & (np.argmax(Yout, axis=1) == np.argmax(T, axis=1)))[itst])\n",
    "            efftot[icv,ithr] = TP / float(len(itst))\n",
    "    plt.errorbar(mlp_thrs, np.mean(efftot, axis=0), np.std(efftot, axis=0), fmt='--k',\n",
    "                 errorevery=10, label='Accuracy')\n",
    "    # Plot System trigger rate\n",
    "    efftrg = np.zeros((NCV, len(mlp_thrs)))*np.nan  # total efficiency (known-classes)    \n",
    "    for icv in range(NCV):\n",
    "        Yout = mlp_out[novcls][icv]\n",
    "        itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        # Loop over thresholds\n",
    "        for ithr, thr in enumerate(mlp_thrs):\n",
    "            # Just need an output greater than the thrshold\n",
    "            TP = np.sum((np.max(Yout, axis=1)[itst]>=thr))\n",
    "            efftrg[icv,ithr] = TP / float(len(itst))\n",
    "    plt.errorbar(mlp_thrs, np.mean(efftrg, axis=0), np.std(efftrg, axis=0), fmt='-.k',\n",
    "                 errorevery=10, label='Trigger')\n",
    "    \n",
    "    # Plot Novelty\n",
    "    for icv in range(NCV):\n",
    "        Ynov = mlp_out_nov[novcls][icv]\n",
    "        effnov[icv] = np.array([np.sum(np.max(Ynov, axis=1) < thr) for thr in mlp_thrs], 'f')/Ynov.shape[0]\n",
    "    plt.errorbar(mlp_thrs, np.nanmean(effnov, axis=0), np.nanstd(effnov, axis=0),\n",
    "                 fmt='k-', errorevery=10, label='Novelty')\n",
    "    # PRINT INFO\n",
    "    #idx = np.nonzero(np.mean(efftrg, axis=0) >= det_target)[0][-1]\n",
    "    #idx = np.nonzero(np.mean(effsp, axis=0) >= det_target)[0][-1]\n",
    "    idx = np.nonzero(np.mean(efftot, axis=0) >= det_target)[0][-1]\n",
    "    print novcls, '  Trig: %5.2f +- %5.2f, Nov: %5.2f +- %5.2f, at thrs: %5.3f'%(np.mean(efftrg, axis=0)[idx]*100,\n",
    "                                                                                 np.std (efftrg, axis=0)[idx]*100,\n",
    "                                                                                 np.mean(effnov, axis=0)[idx]*100,\n",
    "                                                                                 np.std (effnov, axis=0)[idx]*100,\n",
    "                                                                                 mlp_thrs[idx]),\n",
    "    print ' acc: %5.2f +- %5.2f'%(np.mean(efftot, axis=0)[idx]*100, np.std(efftot, axis=0)[idx]*100),\n",
    "    print ' sp: %5.2f +- %5.2f'%(np.mean(effsp, axis=0)[idx]*100, np.std(effsp, axis=0)[idx]*100)\n",
    "    # Operation parameters\n",
    "    best_mlp[novcls] = efftrg[:,idx].argmax()\n",
    "    mlp_det_thr[novcls] = mlp_thrs[idx]\n",
    "    # Plot aspects\n",
    "    plt.gca().set_yticks(np.linspace(0,1,11))\n",
    "    plt.gca().set_xticks(np.arange(-1,1.25,0.25))\n",
    "    plt.xlim([-1,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.grid()\n",
    "    plt.xlabel('Decision Threshold')\n",
    "    plt.ylabel('Efficiency/Outlier Rate')\n",
    "    plt.title('Novelty: ' + novcls)\n",
    "    plt.legend(loc='center left', ncol=2).get_frame().set_facecolor('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Consultive: MLP to ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop over novelty classes\n",
    "plt.figure(figsize=(15,10), facecolor='w')\n",
    "# Loop over novelties\n",
    "art_radius = [0.5, 0.6, 0.8]\n",
    "mlp_nonnov_thr =  0.7\n",
    "mlp_nov_thr = -0.5\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    print 'Novelty: ', novcls\n",
    "    plt.subplot(2,2,inov+1)\n",
    "    NCV = cvPar[novcls]['CVNSel']\n",
    "    T = target[novcls]\n",
    "    leg_handlers = []\n",
    "    leg_labels = []\n",
    "    ############################################################ MLP Alone\n",
    "    # Plot System trigger rate\n",
    "    efftrg = np.zeros((NCV, len(mlp_thrs)))*np.nan  # total efficiency (known-classes)    \n",
    "    for icv in range(NCV):\n",
    "        Yout = mlp_out[novcls][icv]\n",
    "        itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        # Loop over thresholds\n",
    "        for ithr, thr in enumerate(mlp_thrs):\n",
    "            # Just need an output greater than the thrshold\n",
    "            TP = np.sum((np.max(Yout, axis=1)[itst]>=thr))\n",
    "            efftrg[icv,ithr] = TP / float(len(itst))\n",
    "    h = plt.errorbar(mlp_thrs, np.mean(efftrg, axis=0), np.std(efftrg, axis=0), fmt='-.k',\n",
    "                     errorevery=10, label='Trigger')\n",
    "    leg_handlers.append(h)\n",
    "    leg_labels.append('Trigger')\n",
    "    # Plot Novelty\n",
    "    for icv in range(NCV):\n",
    "        Ynov = mlp_out_nov[novcls][icv]\n",
    "        effnov[icv] = np.array([np.sum(np.max(Ynov, axis=1) < thr) for thr in mlp_thrs], 'f')/Ynov.shape[0]\n",
    "    h = plt.errorbar(mlp_thrs, np.nanmean(effnov, axis=0), np.nanstd(effnov, axis=0),\n",
    "                     fmt='k-', errorevery=10, label='Novelty')\n",
    "    leg_handlers.append(h)\n",
    "    leg_labels.append('Novelty')\n",
    "    ############################################################### Associate ART and MLP\n",
    "    for ir, art_th in enumerate(art_radius):\n",
    "        probdist = np.zeros((NCV, len(mlp_thrs)))\n",
    "        probnov = np.zeros((NCV, len(mlp_thrs)))\n",
    "        # Loop over CV\n",
    "        for icv in range(NCV):\n",
    "            # Known-classes\n",
    "            itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "            Ymlp = mlp_out[novcls][icv][itst].max(axis=1)\n",
    "            Yart = art_norm[novcls][icv][itst].max(axis=1)\n",
    "            for i, th in enumerate(mlp_thrs):\n",
    "                if th > mlp_nonnov_thr:\n",
    "                    mlp_dec = (Ymlp >= mlp_nonnov_thr)\n",
    "                elif th > mlp_nonnov_thr:\n",
    "                    mlp_dec = ((Ymlp >= mlp_nonnov_thr) & \\\n",
    "                               ((Ymlp >= th) | ((Ymlp < mlp_nonnov_thr)&(Yart >= art_th))))\n",
    "                else:\n",
    "                    mlp_dec = Ymlp >= mlp_nov_thr\n",
    "                probdist[icv, i] = mlp_dec.sum() / float(len(itst))\n",
    "            # Novelty\n",
    "            Ymlp = mlp_out_nov[novcls][icv].max(axis=1)\n",
    "            Yart = art_norm_nov[novcls][icv].max(axis=1)\n",
    "            for i, th in enumerate(mlp_thrs):\n",
    "                if th < mlp_nov_thr:\n",
    "                    mlp_dec = (Ymlp < mlp_nov_thr)\n",
    "                elif th < mlp_det_thr:\n",
    "                     mlp_dec = ((Ymlp < mlp_nonnov_thr) & \\\n",
    "                                ((Ymlp < mlp_nov_thr) | \\\n",
    "                                 ((Ymlp >= mlp_nov_thr) & (Ymlp < th) & (Yart < art_th))))\n",
    "                else:\n",
    "                    mlp_dec = Ymlp < mlp_nonnov_thr\n",
    "                probnov[icv, i] = (mlp_dec).sum() / float(Ymlp.shape[0])\n",
    "        # Plot Known classes\n",
    "        icls = np.nonzero(classes == novcls)[0][0]\n",
    "        plt.errorbar(mlp_thrs, np.mean(probdist, axis=0), np.std(probdist, axis=0), fmt='-.',\n",
    "                     color=colors[icls], errorevery=10,\n",
    "                     markevery=10, marker=markers[ir])\n",
    "        # Plot Novelty\n",
    "        icls = np.nonzero(classes == novcls)[0][0]\n",
    "        h = plt.errorbar(mlp_thrs, np.mean(probnov, axis=0), np.std(probnov, axis=0), fmt='-',\n",
    "                         color=colors[icls], errorevery=10,\n",
    "                         markevery=10, marker=markers[ir])\n",
    "        leg_handlers.append(h)\n",
    "        leg_labels.append('ART: %.2f'%art_th)\n",
    "    # Plot Confusion Thresholds\n",
    "    plt.plot([mlp_nonnov_thr, mlp_nonnov_thr], [0, 1], 'k--', lw=4)\n",
    "    h = plt.plot([mlp_nov_thr, mlp_nov_thr], [0, 1], 'k--', lw=4)\n",
    "    leg_handlers.append(h[0])\n",
    "    leg_labels.append('Consulting limits')\n",
    "        \n",
    "    plt.title('Trigger and Novelty: ' + novcls)\n",
    "    plt.gca().set_yticks(np.linspace(-1,1,21))\n",
    "    plt.gca().set_xticks(np.linspace(-1,1,11))\n",
    "    #plt.gca().axis([mlp_nov_thr-0.1, mlp_det_thr+0.1,0,1])\n",
    "    plt.gca().axis([-1,1,0,1])\n",
    "    plt.xlabel('MLP Threshold')\n",
    "    plt.ylabel('Efficiency/Outlier Rate')\n",
    "    plt.legend(leg_handlers, leg_labels, loc='best').get_frame().set_facecolor('1')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble: weighting each output by its error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop over novelty classes\n",
    "plt.figure(figsize=(15,10), facecolor='w')\n",
    "# Loop over novelties\n",
    "art_factor = 1\n",
    "ensemble_thrs = art_thrs\n",
    "ens_det_thr = {}\n",
    "best_ens = {}\n",
    "ens_out = {}\n",
    "ens_out_nov = {}\n",
    "det_target = 0.8\n",
    "for inov, novcls in enumerate(noveltyclasses):\n",
    "    plt.subplot(2,2,inov+1)\n",
    "    NCV = cvPar[novcls]['CVNSel']\n",
    "    T = target[novcls]\n",
    "    leg_handlers = []\n",
    "    leg_labels = []\n",
    "    ############################################################ MLP Alone\n",
    "    # Plot System trigger rate\n",
    "    efftrg = np.zeros((NCV, len(ensemble_thrs)))*np.nan  # total efficiency (known-classes)    \n",
    "    effacc = np.zeros((NCV, len(ensemble_thrs)))*np.nan  # total efficiency (known-classes)    \n",
    "    effsps = np.zeros((NCV, len(ensemble_thrs)))*np.nan  # total efficiency (known-classes)    \n",
    "    for icv in range(NCV):\n",
    "        itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        Yout = (mlp_out[novcls][icv][itst].max(axis=1) + 1)/2\n",
    "        Ycls = np.argmax(mlp_out[novcls][icv][itst], axis=1)\n",
    "        Tcls = np.argmax(T[itst], axis=1)\n",
    "        effs = np.zeros((T.shape[1],ensemble_thrs.shape[0]))\n",
    "        # Loop over thresholds\n",
    "        for ithr, thr in enumerate(ensemble_thrs):\n",
    "            # Just need an output greater than the thrshold\n",
    "            TP = (Yout >= thr).sum()\n",
    "            efftrg[icv,ithr] = TP / float(Yout.shape[0])\n",
    "            TP = ((Yout >= thr) & (Ycls == Tcls)).sum()\n",
    "            effacc[icv,ithr] = TP / float(Yout.shape[0])\n",
    "        for icls in range(effs.shape[0]):\n",
    "            effs[icls] = [((Yout >= th) &\n",
    "                           (Ycls == Tcls) &\n",
    "                           (Tcls == icls)).sum()/ float((Tcls==icls).sum()) for th in ensemble_thrs]\n",
    "        effsps[icv] = np.sqrt(np.power(np.prod(effs,axis=0), 1.0/effs.shape[0])*np.mean(effs, axis=0))\n",
    "    \n",
    "    h = plt.errorbar(ensemble_thrs, np.mean(effsps, axis=0), np.std(effsps, axis=0), fmt='o-.k',\n",
    "                     errorevery=10, label='SP', markevery=50)\n",
    "    leg_handlers.append(h)\n",
    "    leg_labels.append('MLP - SP')\n",
    "    h = plt.errorbar(ensemble_thrs, np.mean(effacc, axis=0), np.std(effacc, axis=0), fmt='o--k',\n",
    "                     errorevery=10, label='Accuracy', markevery=50)\n",
    "    leg_handlers.append(h)\n",
    "    leg_labels.append('MLP - Accuracy')\n",
    "    # Plot Novelty\n",
    "    effnov = np.zeros((NCV, len(ensemble_thrs)))*np.nan  \n",
    "    for icv in range(NCV):\n",
    "        Ynov = (mlp_out_nov[novcls][icv].max(axis=1) + 1)/2\n",
    "        effnov[icv] = np.array([(Ynov < thr).sum() for thr in ensemble_thrs], 'f')/Ynov.shape[0]\n",
    "    h = plt.errorbar(ensemble_thrs, np.nanmean(effnov, axis=0), np.nanstd(effnov, axis=0),\n",
    "                     fmt='ok-', errorevery=10, label='Novelty', markevery=50)\n",
    "    leg_handlers.append(h)\n",
    "    leg_labels.append('MLP - Novelty')\n",
    "    ############################################################### Ensemble\n",
    "    probdist = np.zeros((NCV,len(ensemble_thrs))) # Use the ART Threshold\n",
    "    probnov = np.zeros((NCV,len(ensemble_thrs)))\n",
    "    probacc = np.zeros((NCV,len(ensemble_thrs)))\n",
    "    probsps = np.zeros((NCV,len(ensemble_thrs)))  \n",
    "    \n",
    "    ens_out[novcls]     = np.zeros((mlp_out[novcls].shape))\n",
    "    ens_out_nov[novcls] = np.zeros((mlp_out_nov[novcls].shape))\n",
    "    # Loop over CV\n",
    "    for icv in range(NCV):\n",
    "        effs = np.zeros((T.shape[1],ensemble_thrs.shape[0]))\n",
    "        ############################################# Known-classes\n",
    "        itst = cvPar[novcls]['Indexes'][icv]['IVal']\n",
    "        Tcls = np.argmax(T[itst], axis=1)\n",
    "        #Ymlp = (mlp_out[novcls][icv].max(axis=1)+1)/2 # Put output from 0 to 1\n",
    "        #Yart = art_norm[novcls][icv].max(axis=1)\n",
    "        Ymlp = (mlp_out[novcls][icv]+1)/2 # Put output from 0 to 1\n",
    "        Yart = art_norm[novcls][icv]\n",
    "        # Output Weights - MLP\n",
    "        thrstep = mlp_thrs[1] - mlp_thrs[0]\n",
    "        Wmlp = mlp_error[novcls][icv][np.array(np.floor(Ymlp / thrstep), 'i')]\n",
    "        Wmlp[Wmlp == 0] = 1.0\n",
    "        Wmlp = 1./Wmlp\n",
    "        # Output Weights - ART\n",
    "        thrstep = art_thrs[1] - art_thrs[0]\n",
    "        Wart = art_error[novcls][icv][np.array(np.floor(Yart / thrstep), 'i')]\n",
    "        Wart[Wart == 0] = 1.0\n",
    "        Wart = 1./Wart * art_factor\n",
    "        # Ensemple output: weighted average\n",
    "        ens_out[novcls][icv] = (Wmlp*Ymlp + Wart*(Yart)) / (Wart+Wmlp)\n",
    "        Yens = ens_out[novcls][icv][itst]\n",
    "        probdist[icv] = [(Yens.max(axis=1) >= th).sum() / float(Yens.shape[0]) for th in ensemble_thrs]\n",
    "        probacc[icv] = [((Yens.max(axis=1) >= th) & (np.argmax(Yens,axis=1) == Tcls)).sum() / float(Yens.shape[0]) \\\n",
    "                        for th in ensemble_thrs]\n",
    "        for icls in range(effs.shape[0]):\n",
    "            effs[icls] = [((Yens.max(axis=1) >= th) &\n",
    "                           (np.argmax(Yens,axis=1) == Tcls) &\n",
    "                           (Tcls == icls)).sum()/ float((Tcls==icls).sum()) for th in ensemble_thrs]\n",
    "        probsps[icv] = np.sqrt(np.power(np.prod(effs,axis=0), 1.0/effs.shape[0])*np.mean(effs, axis=0))\n",
    "        ############################################# Novelty\n",
    "        #Ymlp = (mlp_out_nov[novcls][icv].max(axis=1)+1)/2 # Put output from 0 to 1\n",
    "        #Yart = art_norm_nov[novcls][icv].max(axis=1)\n",
    "        Ymlp = (mlp_out_nov[novcls][icv]+1)/2 # Put output from 0 to 1\n",
    "        Yart = art_norm_nov[novcls][icv]\n",
    "        # Output Weights - MLP\n",
    "        thrstep = mlp_thrs[1] - mlp_thrs[0]\n",
    "        Wmlp = mlp_error[novcls][icv][np.array(np.floor(Ymlp / thrstep), 'i')]\n",
    "        Wmlp[Wmlp == 0] = 1.0\n",
    "        Wmlp = 1./Wmlp\n",
    "        # Output Weights - ART\n",
    "        thrstep = art_thrs[1] - art_thrs[0]\n",
    "        Wart = art_error[novcls][icv][np.array(np.floor(Yart / thrstep), 'i')]\n",
    "        Wart[Wart == 0] = 1.0\n",
    "        Wart = 1./Wart * art_factor\n",
    "        # Ensemple output: weighted average\n",
    "        Yens = (Wmlp*Ymlp + Wart*(Yart)) / (Wart+Wmlp)\n",
    "        ens_out_nov[novcls][icv] = (Wmlp*Ymlp + Wart*(Yart)) / (Wart+Wmlp)\n",
    "        Yens = ens_out_nov[novcls][icv].max(axis=1)\n",
    "        probnov[icv] = [(Yens < th).sum() / float(Yens.shape[0]) for th in ensemble_thrs]\n",
    "    # Plot Known classes trigger and accuracy\n",
    "    icls = np.nonzero(classes == novcls)[0][0]\n",
    "    h = plt.errorbar(ensemble_thrs, np.mean(probsps, axis=0), np.std(probsps, axis=0), fmt='^-.',\n",
    "                     color=colors[icls], errorevery=10, markevery=(25,50))\n",
    "    leg_handlers.append(h)\n",
    "    leg_labels.append('Ens. - SP')    \n",
    "    h = plt.errorbar(ensemble_thrs, np.mean(probacc, axis=0), np.std(probacc, axis=0), fmt='^--',\n",
    "                     color=colors[icls], errorevery=10, markevery=(25,50))\n",
    "    leg_handlers.append(h)\n",
    "    leg_labels.append('Ens. - Accuracy')    \n",
    "    # Plot Novelty\n",
    "    h = plt.errorbar(ensemble_thrs, np.mean(probnov, axis=0), np.std(probnov, axis=0), fmt='^-',\n",
    "                     color=colors[icls], errorevery=10,markevery=(25,50))\n",
    "    leg_handlers.append(h)\n",
    "    leg_labels.append('Ens. - Novelty')        \n",
    "    # PRINT INFO\n",
    "    idx = np.nonzero(np.mean(probdist, axis=0) >= det_target)[0][-1]\n",
    "    idx = np.nonzero(np.mean(probacc, axis=0) >= det_target)[0][-1]    \n",
    "    print novcls, ' Trg: %5.2f +- %5.2f, Nov: %5.2f +- %5.2f, @ thrs: %5.3f, acc: %5.2f +- %5.2f, sp: %5.2f +- %5.2f'\\\n",
    "                  %(np.mean(probdist, axis=0)[idx]*100,\n",
    "                    np.std (probdist, axis=0)[idx]*100,\n",
    "                    np.mean(probnov, axis=0)[idx]*100,\n",
    "                    np.std (probnov, axis=0)[idx]*100,\n",
    "                    ensemble_thrs[idx],\n",
    "                    np.mean(probacc, axis=0)[idx]*100,\n",
    "                    np.std (probacc, axis=0)[idx]*100,\n",
    "                    np.mean(probsps, axis=0)[idx]*100,\n",
    "                    np.std (probsps, axis=0)[idx]*100)\n",
    "    \n",
    "    # Operation parameters\n",
    "    best_ens[novcls] = efftrg[:,idx].argmax()\n",
    "    ens_det_thr[novcls] = ensemble_thrs[idx]\n",
    "    plt.title('Trigger and Novelty: ' + novcls)\n",
    "    plt.gca().set_yticks(np.linspace(0,1,11))\n",
    "    plt.gca().set_xticks(np.linspace(0,1,11))\n",
    "    plt.gca().axis([0,1,0,1])\n",
    "    plt.xlabel('Ensemble Threshold')\n",
    "    plt.ylabel('Efficiency/Outlier Rate')\n",
    "    plt.legend(leg_handlers, leg_labels, loc='best', ncol=1).get_frame().set_facecolor('1')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Operation Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Time Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Operation = {}\n",
    "raw_data = joblib.load(original_file)\n",
    "nPts = data[noveltyclasses[0]].shape[1]\n",
    "# Loop over classifiers\n",
    "for novcls in noveltyclasses:\n",
    "    Operation[novcls] = {}\n",
    "    Operation[novcls]['Classes'] = raw_data.keys()\n",
    "    Operation[novcls]['MLP'] = {'KnownDetec':{}, 'KnownAsNov':{}, 'NovelAsKnown':{}, 'NovelDet':{}}\n",
    "    Operation[novcls]['ART'] = {'KnownDetec':{}, 'KnownAsNov':{}, 'NovelAsKnown':{}, 'NovelDet':{}}\n",
    "    Operation[novcls]['ENS'] = {'KnownDetec':{}, 'KnownAsNov':{}, 'NovelAsKnown':{}, 'NovelDet':{}}\n",
    "    Operation[novcls]['Timew'] = {}\n",
    "    # Create structures\n",
    "    for cls in raw_data.keys():\n",
    "        for key in Operation[novcls]['MLP'].keys():\n",
    "            Operation[novcls]['MLP'][key][cls] = {}\n",
    "            Operation[novcls]['ART'][key][cls] = {}\n",
    "            Operation[novcls]['ENS'][key][cls] = {}\n",
    "        Operation[novcls]['Timew'][cls] = {}\n",
    "    # Loop over data from each class\n",
    "    for icls, cls in enumerate(raw_data.keys()):\n",
    "        # Each class run\n",
    "        run_start = 0\n",
    "        for run in raw_data[cls].keys():\n",
    "            for key in Operation[novcls]['MLP'].keys():\n",
    "                Operation[novcls]['MLP'][key][cls][run] = {}\n",
    "                Operation[novcls]['ART'][key][cls][run] = {}\n",
    "                Operation[novcls]['ENS'][key][cls][run] = {}\n",
    "            X = raw_data[cls][run]['Signal'][:nPts]\n",
    "            Fs = float(raw_data[cls][run]['Fs'])\n",
    "            Operation[novcls]['Timew'][cls][run] = np.arange(1,X.shape[1]+1) * nfft/Fs            \n",
    "            ############################################################## ART\n",
    "            icv = best_art[novcls]\n",
    "            Y = pcdnet[novcls][icv].W[0].dot(X).T\n",
    "            Y = artnet[novcls][icv].trn_data_norm.transform(Y) \n",
    "            R = artnet[novcls][icv].trn_initial_radius\n",
    "            Y = artnet[novcls][icv].outputs(Y)\n",
    "            dmax = 5*R\n",
    "            Y = 1 - np.tanh(Y/dmax)\n",
    "            Y[Y < 0.5] = 0.5\n",
    "            Y[Y > 0.9] = 0.9\n",
    "            Y = (Y - 0.5) / 0.4\n",
    "            if cls != novcls:\n",
    "                for iout, detcls in enumerate(pcdlabels[novcls]):\n",
    "                    # Detecting known classes as known classes\n",
    "                    tpr = np.array((Y[:, iout] > art_det_thr[novcls]) & (np.argmax(Y, axis=1) == iout), 'f')\n",
    "                    Operation[novcls]['ART']['KnownDetec'][cls][run][detcls] = tpr\n",
    "                    # Detecting known classes as novelties\n",
    "                    tpr = np.array((np.max(Y, axis=1) < art_det_thr[novcls]),'f')\n",
    "                    Operation[novcls]['ART']['KnownAsNov'][cls][run][novcls] = tpr\n",
    "            else:\n",
    "                tpr = np.array((np.max(Y, axis=1) < art_det_thr[novcls]),'f')\n",
    "                Operation[novcls]['ART']['NovelDet'][novcls][run][novcls] = tpr\n",
    "                for iout, detcls in enumerate(pcdlabels[novcls]):\n",
    "                    tpr = np.array((Y[:, iout] > art_det_thr[novcls]) & (np.argmax(Y, axis=1) == iout), 'f')\n",
    "                    Operation[novcls]['ART']['NovelAsKnown'][novcls][run][detcls] = tpr\n",
    "                    \n",
    "            ############################################################## MLP\n",
    "            icv = best_mlp[novcls]\n",
    "            if PCDType == 'pcd_constructive':\n",
    "                Y = pcdnet[novcls][icv].feedforward(X.T)\n",
    "            elif PCDType == 'pcd_independent':\n",
    "                Y = pcdclf[novcls][icv].feedforward(pcdnet[novcls][icv].feedforward(X.T))\n",
    "            if cls != novcls:\n",
    "                for iout, detcls in enumerate(pcdlabels[novcls]):\n",
    "                    # Detecting known classes as known classes\n",
    "                    tpr = np.array((Y[:, iout] > mlp_det_thr[novcls]) & (np.argmax(Y, axis=1) == iout), 'f')\n",
    "                    Operation[novcls]['MLP']['KnownDetec'][cls][run][detcls] = tpr\n",
    "                    # Detecting known classes as novelties\n",
    "                    tpr = np.array((np.max(Y, axis=1) < mlp_det_thr[novcls]),'f')\n",
    "                    Operation[novcls]['MLP']['KnownAsNov'][cls][run][novcls] = tpr\n",
    "            else:\n",
    "                tpr = np.array((np.max(Y, axis=1) < mlp_det_thr[novcls]),'f')\n",
    "                Operation[novcls]['MLP']['NovelDet'][novcls][run][novcls] = tpr\n",
    "                for iout, detcls in enumerate(pcdlabels[novcls]):\n",
    "                    tpr = np.array((Y[:, iout] > mlp_det_thr[novcls]) & (np.argmax(Y, axis=1) == iout), 'f')\n",
    "                    Operation[novcls]['MLP']['NovelAsKnown'][novcls][run][detcls] = tpr \n",
    "                    \n",
    "            ############################################################## ENS\n",
    "            icv = best_ens[novcls]\n",
    "            # MLP\n",
    "            if PCDType == 'pcd_constructive':\n",
    "                Ymlp = pcdnet[novcls][icv].feedforward(X.T)\n",
    "            elif PCDType == 'pcd_independent':\n",
    "                Ymlp = pcdclf[novcls][icv].feedforward(pcdnet[novcls][icv].feedforward(X.T))\n",
    "            Ymlp = (Ymlp + 1)/2.0\n",
    "            thrstep = mlp_thrs[1] - mlp_thrs[0]\n",
    "            Wmlp = mlp_error[novcls][icv][np.array(np.floor(Ymlp / thrstep), 'i')]\n",
    "            Wmlp[Wmlp == 0] = 1.0\n",
    "            Wmlp = 1./Wmlp            \n",
    "            # ART\n",
    "            Yart = pcdnet[novcls][icv].W[0].dot(X).T\n",
    "            Yart = artnet[novcls][icv].trn_data_norm.transform(Yart) \n",
    "            R = artnet[novcls][icv].trn_initial_radius\n",
    "            Yart = artnet[novcls][icv].outputs(Yart)\n",
    "            dmax = 5*R\n",
    "            Yart = 1 - np.tanh(Yart/dmax)\n",
    "            Yart[Yart < 0.5] = 0.5\n",
    "            Yart[Yart > 0.9] = 0.9\n",
    "            Yart = (Yart - 0.5) / 0.4\n",
    "            thrstep = art_thrs[1] - art_thrs[0]\n",
    "            Wart = art_error[novcls][icv][np.array(np.floor(Yart / thrstep), 'i')]\n",
    "            Wart[Wart == 0] = 1.0\n",
    "            Wart = 1./Wart * art_factor\n",
    "            # Ensemble\n",
    "            Yens = (Wmlp*Ymlp + Wart*(Yart)) / (Wart+Wmlp)\n",
    "            if cls != novcls:\n",
    "                for iout, detcls in enumerate(pcdlabels[novcls]):\n",
    "                    # Detecting known classes as known classes\n",
    "                    tpr = np.array((Yens[:, iout] > ens_det_thr[novcls]) & (np.argmax(Yens, axis=1) == iout), 'f')\n",
    "                    Operation[novcls]['ENS']['KnownDetec'][cls][run][detcls] = tpr\n",
    "                    # Detecting known classes as novelties\n",
    "                    tpr = np.array((np.max(Yens, axis=1) < ens_det_thr[novcls]),'f')\n",
    "                    Operation[novcls]['ENS']['KnownAsNov'][cls][run][novcls] = tpr\n",
    "            else:\n",
    "                tpr = np.array((np.max(Yens, axis=1) < ens_det_thr[novcls]),'f')\n",
    "                Operation[novcls]['ENS']['NovelDet'][novcls][run][novcls] = tpr\n",
    "                for iout, detcls in enumerate(pcdlabels[novcls]):\n",
    "                    tpr = np.array((Yens[:, iout] > ens_det_thr[novcls]) & (np.argmax(Yens, axis=1) == iout), 'f')\n",
    "                    Operation[novcls]['ENS']['NovelAsKnown'][novcls][run][detcls] = tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of Known Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulated efficiency is w.r.t. data from its own class. This measurement is considering the 'recall' characteristics. That is, the probability to detect class A if the classifier is fed with data from class A. That is why the probabilities do not sum up to 1. The values presented should be compared to the individual and ensemble detection effiencies shown earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tot_t = 20 # seconds\n",
    "for imethod, method in enumerate(['ART','MLP','ENS']):\n",
    "    plt.figure(figsize=(20,5), facecolor='w')\n",
    "    plt.suptitle('Method: ' + method)\n",
    "    # Loop over novelties\n",
    "    for inov, novcls in enumerate(noveltyclasses):\n",
    "        plt.subplot(1,4,inov+1)\n",
    "        # Loop over data from known classes\n",
    "        for cls in Operation[novcls][method]['KnownDetec'].keys():\n",
    "            if cls == novcls: continue\n",
    "            # Sample rate is always the same\n",
    "            tot_samples = int(tot_t / Operation[novcls]['Timew'][cls][0][0])\n",
    "            N = np.sum([int(Operation[novcls]['Timew'][cls][run][-1] / tot_t) \n",
    "                        for run in Operation[novcls][method]['KnownDetec'][cls].keys()])\n",
    "            window_eff = np.zeros((N, tot_samples))\n",
    "            timew = np.linspace(Operation[novcls]['Timew'][cls][0][0], tot_t, tot_samples)  \n",
    "            win_run_idx = 0\n",
    "            n = 0\n",
    "            for run in Operation[novcls][method]['KnownDetec'][cls].keys():\n",
    "                tot_n = int(Operation[novcls]['Timew'][cls][run][-1] / tot_t)\n",
    "                n = n + tot_n\n",
    "                for iwin in range(tot_n):\n",
    "                    tpr = Operation[novcls][method]['KnownDetec'][cls][run][cls][iwin * tot_samples : (iwin+1)*tot_samples]\n",
    "                    window_eff[win_run_idx] = np.cumsum(tpr) / np.arange(1, len(tpr)+1)\n",
    "                    win_run_idx = win_run_idx + 1\n",
    "            # Plot\n",
    "            icls = np.nonzero(classes == cls)[0][0]\n",
    "            plt.errorbar(timew,  np.mean(window_eff, axis=0), np.std(window_eff, axis=0),\n",
    "                         errorevery=20, dashes=dashes[icls],color=colors[icls],label=cls,\n",
    "                         marker=markers[icls], markevery=20)\n",
    "        # Plot labels\n",
    "        plt.ylim([0.5,1])\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Cumulative Detection Rate')\n",
    "        plt.title('Novelty: ' + novcls)\n",
    "        plt.legend(loc='lower center', ncol=3, handlelength=0.3,borderpad=0.3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 'False Alarm' for the Novelty Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots considers the amount of time windows that are identified as novelty, eventhough the data represents known classes. The ideia is to see which classes are more similar to the novelty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tot_t = 20 # seconds\n",
    "for imethod, method in enumerate(['ART','MLP','ENS']):\n",
    "    plt.figure(figsize=(20,5), facecolor='w')\n",
    "    plt.suptitle('Method: ' + method)\n",
    "    # Loop over novelties\n",
    "    for inov, novcls in enumerate(noveltyclasses):\n",
    "        plt.subplot(1,4,inov+1)\n",
    "        # Loop over data from known classes\n",
    "        for cls in Operation[novcls][method]['KnownAsNov'].keys():\n",
    "            if cls == novcls: continue\n",
    "            # Sample rate is always the same\n",
    "            tot_samples = int(tot_t / Operation[novcls]['Timew'][cls][0][0])\n",
    "            N = np.sum([int(Operation[novcls]['Timew'][cls][run][-1] / tot_t) \n",
    "                        for run in Operation[novcls][method]['KnownAsNov'][cls].keys()])\n",
    "            window_eff = np.zeros((N, tot_samples))\n",
    "            timew = np.linspace(Operation[novcls]['Timew'][cls][0][0], tot_t, tot_samples)  \n",
    "            win_run_idx = 0\n",
    "            n = 0\n",
    "            for run in Operation[novcls][method]['KnownAsNov'][cls].keys():\n",
    "                tot_n = int(Operation[novcls]['Timew'][cls][run][-1] / tot_t)\n",
    "                n = n + tot_n\n",
    "                for iwin in range(tot_n):\n",
    "                    tpr = Operation[novcls][method]['KnownAsNov'][cls][run][novcls]\\\n",
    "                                   [iwin * tot_samples : (iwin+1)*tot_samples]\n",
    "                    window_eff[win_run_idx] = np.cumsum(tpr) / np.arange(1, len(tpr)+1)\n",
    "                    win_run_idx = win_run_idx + 1\n",
    "            # Plot\n",
    "            icls = np.nonzero(classes == cls)[0][0]\n",
    "            plt.errorbar(timew,  np.mean(window_eff, axis=0), np.std(window_eff, axis=0),\n",
    "                         errorevery=20, dashes=dashes[icls],color=colors[icls],label=cls)\n",
    "        # Plot labels\n",
    "        plt.ylim([0,0.4])\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Cumulative Detection Rate')\n",
    "        plt.title('Novelty: ' + novcls)\n",
    "        plt.legend(loc='best', ncol=3, handlelength=0.3,borderpad=0.3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of Novel Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show the behavior of the classifier when data from new class is presented. The classifier identifies the data as a new class or its response fell over one of the known classes. The total rate should sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tot_t = 20 # seconds\n",
    "for imethod, method in enumerate(['ART','MLP','ENS']):\n",
    "    plt.figure(figsize=(20,5), facecolor='w')\n",
    "    plt.suptitle('Method: ' + method)\n",
    "    # Loop over novelties\n",
    "    for inov, novcls in enumerate(noveltyclasses):\n",
    "        plt.subplot(1,4,inov+1)\n",
    "        # Loop over data from known classes\n",
    "        for cls in Operation[novcls][method]['NovelAsKnown'].keys():\n",
    "            if cls == novcls: continue\n",
    "            # Sample rate is always the same\n",
    "            tot_samples = int(tot_t / Operation[novcls]['Timew'][novcls][0][0])\n",
    "            N = np.sum([int(Operation[novcls]['Timew'][novcls][run][-1] / tot_t) \n",
    "                        for run in Operation[novcls][method]['NovelAsKnown'][novcls].keys()])\n",
    "            window_eff = np.zeros((N, tot_samples))\n",
    "            timew = np.linspace(Operation[novcls]['Timew'][novcls][0][0], tot_t, tot_samples)  \n",
    "            win_run_idx = 0\n",
    "            n = 0\n",
    "            for run in Operation[novcls][method]['NovelAsKnown'][novcls].keys():\n",
    "                tot_n = int(Operation[novcls]['Timew'][novcls][run][-1] / tot_t)\n",
    "                n = n + tot_n\n",
    "                for iwin in range(tot_n):\n",
    "                    tpr = Operation[novcls][method]['NovelAsKnown'][novcls][run][cls]\\\n",
    "                                   [iwin * tot_samples : (iwin+1)*tot_samples]\n",
    "                    window_eff[win_run_idx] = np.cumsum(tpr) / np.arange(1, len(tpr)+1)\n",
    "                    win_run_idx = win_run_idx + 1\n",
    "            # Plot\n",
    "            icls = np.nonzero(classes == cls)[0][0]\n",
    "            plt.errorbar(timew,  np.mean(window_eff, axis=0)*100, np.std(window_eff, axis=0)*100,\n",
    "                         errorevery=20, dashes=dashes[icls],color=colors[icls],label=cls)\n",
    "        # Plot novelty\n",
    "        tot_samples = int(tot_t / Operation[novcls]['Timew'][novcls][0][0])\n",
    "        N = np.sum([int(Operation[novcls]['Timew'][novcls][run][-1] / tot_t) \n",
    "                    for run in Operation[novcls][method]['NovelDet'][novcls].keys()])\n",
    "        window_eff = np.zeros((N, tot_samples))\n",
    "        timew = np.linspace(Operation[novcls]['Timew'][novcls][0][0], tot_t, tot_samples)  \n",
    "        win_run_idx = 0\n",
    "        n = 0\n",
    "        for run in Operation[novcls][method]['NovelDet'][novcls].keys():\n",
    "            tot_n = int(Operation[novcls]['Timew'][novcls][run][-1] / tot_t)\n",
    "            n = n + tot_n\n",
    "            for iwin in range(tot_n):\n",
    "                tpr = Operation[novcls][method]['NovelDet'][novcls][run][novcls]\\\n",
    "                               [iwin * tot_samples : (iwin+1)*tot_samples]\n",
    "                window_eff[win_run_idx] = np.cumsum(tpr) / np.arange(1, len(tpr)+1)\n",
    "                win_run_idx = win_run_idx + 1\n",
    "        # Plot\n",
    "        icls = np.nonzero(classes == cls)[0][0]\n",
    "        plt.errorbar(timew,  np.mean(window_eff, axis=0)*100, np.std(window_eff, axis=0)*100,\n",
    "                     errorevery=20, dashes=dashes[icls],color='k',label='Novelty')\n",
    "        # Plot labels\n",
    "        plt.ylim([0,100])\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('False Alarm/Outliers Percentage [%]')\n",
    "        plt.title('Novelty: ' + novcls)\n",
    "        plt.legend(loc='upper center', ncol=2, handlelength=0.3,borderpad=0.3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
